```html index.html
<!DOCTYPE html>
<html>
  <head>
    <title>Audio Device Selection</title>
    <script src="https://unpkg.com/peerjs@1.5.4/dist/peerjs.min.js"></script>
    <script src="audio.js"></script>
    <script src="peer-connection.js"></script>
    <script src="index.js"></script>
    <script src="worklet-recorder.js"></script>
  </head>
  <body onload="start()">
    <div id="audioConfig">
      <button id="startButton">Start</button>
    </div>
    <div id='peerStatus'></div>
    <div id='gainController'></div>

    <div id='recordingControls'>
      <button id='recordButton'>Record</button>
    </div>
    <div id='audioSnippets'></div>
  </body>
</html>

```

```html sync.html
<!DOCTYPE html>
<html>
  <head>
    <title>SyncedDBMap Demo</title>
    <script src="https://unpkg.com/peerjs@1.5.4/dist/peerjs.min.js"></script>
    <script src="indexed-db-map.js"></script>
    <script src="peer-connection.js"></script>
    <script src="mute-button.js"></script>
    <script>
      let syncedDBMap;

      async function startDemo() {
	  const startButton = document.getElementById('startButton');
	  startButton.remove();
	  // We create these  nodes but don't wire them up for this demo.
	  const audioCtx = new AudioContext();
	  const peerInputNode = audioCtx.createGain();
	  const peerOutputNode = audioCtx.createGain();
	  const div1 = document.getElementById('div1');

	  console.log('Creating peer connection.');
	  
	  const peerConnection = new PeerConnection(
	      'syncDemoConnectionId', peerInputNode, peerOutputNode);
	  
          syncedDBMap = new SyncedDBMap(
	      'syncDemoDB', peerConnection);

          syncedDBMap.localMap.addEventListener('dataChanged', (event) => {
	      console.log('dataChanged event from DB');
              div1.textContent = event.detail.value;
              document.getElementById('div2').textContent = event.detail.value;
          });

	  div1.addEventListener('input', updateContent);
      }

      async function updateContent() {
	  console.log('input event from HTML');
          const content = document.getElementById('div1').textContent;
	  console.log(`Content: ${content}`);
          await syncedDBMap.set('sharedContent', content);
      }
    </script>
  </head>
  <body>
    <button onclick="startDemo()" id='startButton'>Start Demo</button>
    <div>
      <h2>Div 1</h2>
      <div contenteditable='true' id="div1"></div>
    </div>
    <div>
      <h2>Div 2</h2>
      <div contenteditable='true' id="div2"></div>
    </div>
    <div>
      <mute-button id='myMute'></mute-button>
      </div>
  </body>
</html>

```

```js audio.js
class AudioManager {
    constructor() {
	this.audioCtx = null;
	this.localOutputNode = null;
	this.localInputNode = null;

	// Maps a device ID to the AudioNode for that device.
	this.rawInputSources = new Map();
	this.inputDevices = [];
	this.outputDevices = [];
	this.isRecording = false;
	this.recordingBuffer = null;
	this.samplesRecorded = 0;
    }
    
    ctx() {
	return this.audioCtx;
    }

    async initialize() {
	this.audioCtx = new AudioContext();
	this.localOutputNode = this.audioCtx.createGain();
	this.localInputNode = this.audioCtx.createGain();


	new VUMeter(this.localInputNode, document.body, 'mic');
	this.localOutputVU = new VUMeter(
	    this.localOutputNode, document.body, 'speakers');
	this.localOutputNode.connect(this.audioCtx.destination);

	await this.enumerateDevices();

	const recordButton = document.getElementById('recordButton');
	recordButton.addEventListener(
	    'click', () => { this._toggleRecording(); });

	// Create a worklet recorder and add it to the graph.
	await this.audioCtx.audioWorklet.addModule('worklet-recorder.js');
	this.workletRecorderNode = new AudioWorkletNode(
	    this.audioCtx, 'worklet-recorder');
	this.localInputNode.connect(this.workletRecorderNode);
	this.workletRecorderNode.port.onmessage = (event) => {
	    this._processRecordingData(event.data);
	}
    }

    _processRecordingData(data) {
	if (!this.isRecording) {
	    return;
	}
	if (this.samplesRecorded + data.samples.length >
	    this.recordingBuffer.length) {
	    // Add a second to the recording buffer.
	    const newBuffer = new Float32Array(this.recordingBuffer.length +
					       this.audioCtx.sampleRate);
	    newBuffer.set(this.recordingBuffer);
	    this.recordingBuffer = newBuffer;
	}
	this.recordingBuffer.set(data.samples, this.samplesRecorded);
	this.samplesRecorded += data.length;
    }
    
    _toggleRecording() {
	if (this.isRecording) {
	    // TODO: Raise the event with the new, complete buffer
	    this.recordingBuffer = null;
	} else {
	    this.recordingBuffer = new Float32Array(this.audioCtx.sampleRate);
	}
	this.isRecording = !this.isRecording;
    }

    async addAudioInput(deviceId) {
	if (!this.rawInputSources.has(deviceId)) {
	    const stream = await navigator.mediaDevices.getUserMedia({
		audio: {
		    deviceId: deviceId,
		    echoCancellation: false,
		    noiseSuppression: false,
		    autoGainControl: false,
		    latencyHint: 'low',
		},
	    });
	    this.rawInputSources.set(
		deviceId, this.audioCtx.createMediaStreamSource(stream));
	}
	// new VUMeter(this.rawInputSource, document.body);
	
	this.rawInputSources.get(deviceId).connect(this.localInputNode);
	console.log(`Input device added: ${deviceId}`);
	return;  // Explicit return so that `await` works.
    }

    async removeAudioInput(deviceId) {
	if (this.rawInputSources.has(deviceId)) {
	    this.rawInputSources.get(deviceId).disconnect();
	}
    }

    async changeAudioOutput(deviceId) {
	if (!this.audioCtx || !this.localOutputNode) {
	    console.error("AudioContext or localOutputNode not initialized.");
	    return;
	}

	await this.audioCtx.setSinkId(deviceId);
	console.log(`Output device changed to: ${deviceId}`);
	return;  // Explicit return so that `await` works.
    }

    async enumerateDevices() {
	console.log('Scanning...');
	const devices = await navigator.mediaDevices.enumerateDevices();
	console.log('Enumerating...');
	const inputDevices = devices.filter(
	    device => device.kind === 'audioinput');
	const outputDevices = devices.filter(
	    device => device.kind === 'audiooutput' &&
		device.deviceId !== 'default');
	this.inputDevices = inputDevices;
	this.outputDevices = outputDevices;

	console.log(`Inputs: ${inputDevices.length};`);
	console.log(`Outputs: ${outputDevices.length}`);
    }

    inputSelector(div) {
	const inputList = document.createElement('div');
	inputList.innerHTML = "<H1>Inputs</H1>";
	div.appendChild(inputList);
	for (const device of this.inputDevices) {
	    const checkbox = document.createElement('input');
	    checkbox.type = 'checkbox';
	    checkbox.name = 'inputDevice';
	    checkbox.value = device.deviceId;
	    checkbox.id = `inputDevice_${device.deviceId}`;
	    const label = document.createElement('label');
	    label.htmlFor = `inputDevice_${device.deviceId}`;
	    label.textContent = device.label || device.deviceId;
	    inputList.appendChild(checkbox);
	    inputList.appendChild(label);
	    inputList.appendChild(document.createElement('br'));
	    checkbox.addEventListener('change', async() => {
		console.log(`Value: ${checkbox.value}`);
		if (checkbox.checked) {
		    await this.addAudioInput(checkbox.value);
		} else {
		    await this.removeAudioInput(checkbox.value);
		}
	    });
	}
    }

    outputSelector(div) {
	const outputList = document.createElement('div');
	outputList.innerHTML = "<H2>Outputs</H2>"
	div.appendChild(outputList);
	for (const device of this.outputDevices) {
	    const radio = document.createElement('input');
	    radio.type = 'radio';
	    radio.name = 'outputDevice';
	    radio.value = device.deviceId;
	    radio.id = `outputDevice_${device.deviceId}`;
	    const label = document.createElement('label');
	    label.htmlFor = `outputDevice_${device.deviceId}`;
	    label.textContent = device.label || device.deviceId;
	    outputList.appendChild(radio);
	    outputList.appendChild(label);
	    outputList.appendChild(document.createElement('br'));
	    radio.addEventListener('change', async() => {
		console.log(`Value: ${radio.value}`);
		await this.changeAudioOutput(radio.value);
	    });
	}
    }
}

class GainController {
    constructor(inputNode, outputNode, inputPeerNode, outputPeerNode, parentDiv) {
        this.inputNode = inputNode;
        this.outputNode = outputNode;
        this.inputPeerNode = inputPeerNode;
        this.outputPeerNode = outputPeerNode;
        this.parentDiv = parentDiv;
        this.audioContext = inputNode.context;

	this.parentDiv.innerHTML = "<H1>Monitoring</H1>";

        this.inputToOutputGain = this.audioContext.createGain();
        this.inputToPeerOutputGain = this.audioContext.createGain();
        this.peerInputToOutputGain = this.audioContext.createGain();
        this.peerInputToPeerOutputGain = this.audioContext.createGain();

        this.inputNode.connect(this.inputToOutputGain);
        this.inputToOutputGain.connect(this.outputNode);

        this.inputNode.connect(this.inputToPeerOutputGain);
        this.inputToPeerOutputGain.connect(this.outputPeerNode);

        this.inputPeerNode.connect(this.peerInputToOutputGain);
        this.peerInputToOutputGain.connect(this.outputNode);

        this.inputPeerNode.connect(this.peerInputToPeerOutputGain);
        this.peerInputToPeerOutputGain.connect(this.outputPeerNode);

        this._createSlider("Input to Output Gain",
			   this.inputToOutputGain, -30);
        this._createSlider("Input to Peer Output Gain",
			   this.inputToPeerOutputGain, 0);
        this._createSlider("Peer Input to Output Gain",
			   this.peerInputToOutputGain, 0);
        this._createSlider("Peer Input to Peer Output Gain",
			   this.peerInputToPeerOutputGain, -30);

	new VUMeter(this.outputPeerNode, document.body, 'send');
	new VUMeter(this.inputPeerNode, document.body, 'recieve');
    }

    dbToGain(x) {
        return x <= -30 ?
	    0 : Math.pow(10, x / 20);
    }
    
    _createSlider(labelText, gainNode, initialValue = 0) {
        const container = document.createElement('div');
        const label = document.createElement('label');
        label.textContent = labelText;
        const slider = document.createElement('input');
        slider.type = 'range';
        slider.min = -30;
        slider.max = 10;
        slider.step = 1;
        slider.value = initialValue;
	gainNode.gain.value = this.dbToGain(initialValue);
	
        slider.addEventListener('input', () => {
            const gainValue = parseFloat(slider.value);
            gainNode.gain.value = this.dbToGain(gainValue);
        });

        container.appendChild(label);
        container.appendChild(slider);
        this.parentDiv.appendChild(container);
    }
}

class VUMeter {
    constructor(audioNode, parentDiv, labelText) {
        this.audioNode = audioNode;
        this.parentDiv = parentDiv;
        this._analyser = audioNode.context.createAnalyser();
        this.audioNode.connect(this._analyser);
        this._analyser.fftSize = 2048;
        this.dataArray = new Uint8Array(this._analyser.frequencyBinCount);

        this.containerDiv = document.createElement('div');

        this.labelElement = document.createElement('span');
        this.labelElement.textContent = labelText + ': ';
        this.containerDiv.appendChild(this.labelElement);

        this.vuMeterElement = document.createElement('div');
        this.vuMeterElement.style.width = '0%';
        this.vuMeterElement.style.height = '10px';
        this.vuMeterElement.style.backgroundColor = 'green';
        this.containerDiv.appendChild(this.vuMeterElement);

        this.parentDiv.appendChild(this.containerDiv);

        this._tick = this._tick.bind(this);
        this._tick();
    }

    analyser() {
	return this._analyser;
    }

    _tick() {
        this._analyser.getByteFrequencyData(this.dataArray);
        let maxValue = 0;
        for (let i = 0; i < this.dataArray.length; i++) {
            maxValue = Math.max(maxValue, this.dataArray[i]);
        }
        this.vuMeterElement.style.width = `${0.1 + maxValue / 2.55}%`; // Scale to 0-100%
        requestAnimationFrame(this._tick);
    }
}

```

```js index.js
function createTestToneButton(outputNode) {
    const button = document.createElement('button');
    button.textContent = 'Play Test Tone';
    document.body.appendChild(button);
    const audioContext = outputNode.context;
    const oscillator = audioContext.createOscillator();
    const gainNode = audioContext.createGain();

    gainNode.gain.value = 0;
    
    oscillator.connect(gainNode);
    gainNode.connect(outputNode);
    // gainNode.connect(audioContext.destination);
    oscillator.start();
    
    button.addEventListener('click', () => {
        const startTime = audioContext.currentTime;
        const endTime = startTime + 1;
        gainNode.gain.linearRampToValueAtTime(0.2, startTime + 0.01);
        gainNode.gain.linearRampToValueAtTime(0.2, endTime - 0.01);
        gainNode.gain.linearRampToValueAtTime(0, endTime);
    });
}

function start() {
    document.getElementById('startButton').addEventListener('click', async () => {
	const audioDiv = document.getElementById('audioConfig');
	audioDiv.innerHTML = '';

	const audioManager = new AudioManager();
	await audioManager.initialize();
	audioManager.inputSelector(audioDiv);
	audioManager.outputSelector(audioDiv);

	// Create a couple of nodes we will use to manage the transient connections
	// with our peer.
	const peerInputNode = audioManager.ctx().createGain();
	const peerOutputNode = audioManager.ctx().createGain();

	const gainControllerDiv = document.getElementById('gainController');
	const gainController = new GainController(
	    audioManager.localInputNode, audioManager.localOutputNode,
	    peerInputNode, peerOutputNode,
	    gainControllerDiv);

	createTestToneButton(audioManager.localOutputNode);

	// Attempt to establish the peer connection.
	const peerStatus = document.getElementById('peerStatus');
	const peerConnection = new PeerConnection(
	    "HelloTwinZ2", peerInputNode, peerOutputNode);
	
	peerConnection.addEventListener('peerStreamEstablished', (event) => {
            console.log('Peer stream established in index.js');

	    
	    // TODO: make the call.
	});
	
    });
}

```

```js indexed-db-map.js
class IndexedDBMap {
    constructor(databaseName) {
	this.databaseName = databaseName;
	this.dbPromise = this.openDatabase();
    }

    async openDatabase() {
	return new Promise((resolve, reject) => {
	    const request = indexedDB.open(this.databaseName, 1);

	    request.onupgradeneeded = (event) => {
		const db = event.target.result;
		if (!db.objectStoreNames.contains('map')) {
		    db.createObjectStore('map', { keyPath: 'key' });
		}
	    };

	    request.onsuccess = (event) => {
		resolve(event.target.result);
	    };

	    request.onerror = (event) => {
		reject(event.target.error);
	    };
	});
    }

    async get(key) {
	console.assert(!!key);
	const db = await this.dbPromise;
	const tx = db.transaction('map', 'readonly');
	const store = tx.objectStore('map');
	const request = store.get(key);

	return new Promise((resolve, reject) => {
	    request.onsuccess = (event) => {
		resolve(event.target.result?.value); 
	    };
	    request.onerror = (event) => {
		reject(event.target.error);
	    };
	});
    }
    
    async set(key, value, version) {
	// console.log(`IndexedDBMap set ${value}`);
        const db = await this.dbPromise;
	const tx = db.transaction('map', 'readwrite');
	const store = tx.objectStore('map');
	const request = store.put({ key, value, version });

	return new Promise((resolve, reject) => {
	    request.onsuccess = () => resolve();
	    request.onerror = (event) => reject(event.target.error);
	    tx.oncomplete = () => resolve(); 
	});
    }

    async contains(key) {
	const db = await this.dbPromise;
	const tx = db.transaction('map', 'readonly');
	const store = tx.objectStore('map');
	const request = store.get(key);

	return new Promise((resolve, reject) => {
	    request.onsuccess = (event) => {
		resolve(event.target.result !== undefined); 
	    };
	    request.onerror = (event) => {
		reject(event.target.error);
	    };
	});
    }
}

class ObservableIndexedDBMap extends EventTarget {
    constructor(databaseName) {
	super(); 
	this.map = new IndexedDBMap(databaseName); 
    }

    async get(key) {
	console.assert(!!key);
	return this.map.get(key);
    }

    _makeVersion() {
	return `${Date.now()}-${Math.random().toString(36).substring(2, 15)}`;
    }

    async set(key, value, version = undefined) {
	// console.log(`ObservableIndexedDBMap set ${value}`);
	if (!version) {
	    version = this._makeVersion();
	} else {
	    const currentValue = await this.get(key);
	    if (currentValue && currentValue.version === version) {
		// Nothing to do - we already have the latest version.
		return false;
	    }
	}
	await this.map.set(key, value, version);
	this.dispatchEvent(new CustomEvent('dataChanged', {
	    detail: { key, value, version } }));
	return true;
    }

    async contains(key) {
	return this.map.contains(key);
    }
}

class SyncedDBMap {
    constructor(databaseName, peerConnection) {
	this.localMap = new ObservableIndexedDBMap(databaseName);
	this.peerConnection = peerConnection;
	this._attachHandlers();
    }

    async _attachHandlers() {
	await this.peerConnection.waitForConnection();

	console.log('Peer connection established.');
	this.peerConnection.addEventListener('remoteDataReceived', (event) => {
	    // console.log('Data reached DB');
	    // console.log(event.detail);
	    
	    this._setInternal(
		event.detail.key, event.detail.value, event.detail.version);
	});
	console.log('Synchronization handlers attached.');
    }

    async get(key) {
	return this.localMap.get(key);
    }

    async set(key, value, version = undefined) {
	// console.log(`SyncedDBMap set ${value}`);
	await this._setInternal(key, value, version);
	this._sendUpdate(key, value, version);
    }

    async _setInternal(key, value, version = undefined) {
	this.localMap.set(key, value, version);
    }

    async contains(key) {
	return this.localMap.contains(key);
    }

    _sendUpdate(key, value, version) {
	// console.log(`send update ${value}`);
	if (this.peerConnection.conn && this.peerConnection.conn.open) {
	    this.peerConnection.sendMessage({
		type: 'db-sync',
		key: key,
		value: value,
		version: version,
		source: 'local',
	    });
	}
    }
}

```

```js mute-button.js
class MuteButton extends HTMLElement {
    constructor() {
        super();
        this.attachShadow({ mode: 'open' });
        this.muted = true;
        this.pushToTalk = false;
        this.playbackActive = false;
        this._previousPushToTalkState = false;

        this.shadowRoot.innerHTML = `
            <style>
            :host {
                display: inline-block;
            }
            .mute-container {
                display: flex;
                align-items: center;
            }
            .mute-button {
                background-color: #f0f0f0;
                border: 1px solid #ccc;
                padding: 10px 15px;
                cursor: pointer;
                border-radius: 5px;
                margin-right: 10px;
                user-select: none; /* Prevent text selection on click */
            }
            .mute-button.muted {
                background-color: #ddd;
            }
            .mute-button.talking {
                background-color: lightgreen;
            }
           .mute-button:disabled {
                opacity: 0.5;
                cursor: not-allowed;
            }
            .push-to-talk-switch {
                display: flex;
                align-items: center;
            }
            .push-to-talk-switch input[type="checkbox"] {
               opacity: 0;
               position: absolute;
               }
            .push-to-talk-switch label {
               cursor: pointer;
               padding: 5px;
            }
            .push-to-talk-switch label::before {
               content: '';
               display: inline-block;
               width: 20px;
               height: 10px;
               border: 2px solid #ccc;
               border-radius: 10px;
               background-color: #ccc;
               vertical-align: middle;
               margin-right: 5px;
            }
            .push-to-talk-switch input[type="checkbox"]:checked + label::before {
               background-color: lightgreen;
            }
           .push-to-talk-switch input[type="checkbox"]:checked + label::after {
                content: '';
                display: inline-block;
                width: 10px;
                height: 10px;
                border-radius: 50%;
                background-color: #fff;
                margin-left: 10px;
                position: relative;
                top: -2px;
           }
           .push-to-talk-switch input[type="checkbox"]:disabled + label {
                opacity: 0.5;
                cursor: not-allowed;
           }

            </style>
            <div class="mute-container">
                <div class="mute-button muted" tabindex="0">Mute</div>
                <div class="push-to-talk-switch">
                  <input type="checkbox" id="pushToTalkSwitch">
                  <label for="pushToTalkSwitch">Push to Talk</label>
                </div>
            </div>
        `;
	this.muteButton = this.shadowRoot.querySelector('.mute-button');
	this.pushToTalkSwitch = this.shadowRoot.querySelector('#pushToTalkSwitch');
        this.pushToTalkLabel = this.shadowRoot.querySelector('label[for="pushToTalkSwitch"]');
	this._attachEventListeners();
    }

  _attachEventListeners() {
    this.muteButton.addEventListener('click', this._handleMuteClick.bind(this));
    this.pushToTalkSwitch.addEventListener('change', this._handlePushToTalkChange.bind(this));
        this.muteButton.addEventListener('mousedown', this._handleMuteMouseDown.bind(this));
        this.muteButton.addEventListener('mouseup', this._handleMuteMouseUp.bind(this));
	// Handle keyboard accessibility.
	this.muteButton.addEventListener('keydown', (event) => {
	    if (event.code === 'Space' || event.code === 'Enter') {
		this._handleMuteClick();
	    }
	});
  }


    _handleMuteClick() {
        if (!this.playbackActive) {
            this.muted = !this.muted;
	    this._updateMuteButtonState();
            this.dispatchEvent(new CustomEvent('mutechange', { detail: this.muted }));
        }
    }

     _handleMuteMouseDown() {
      if (this.playbackActive && this.pushToTalk) {
          this.muted = false;
          this._updateMuteButtonState();
	  this.dispatchEvent(new CustomEvent('mutechange', { detail: this.muted }));
	  
      }
    }

    _handleMuteMouseUp() {
        if (this.playbackActive && this.pushToTalk) {
            this.muted = true;
            this._updateMuteButtonState();
	    this.dispatchEvent(new CustomEvent('mutechange', { detail: this.muted }));
       }
    }


    _handlePushToTalkChange() {
        this.pushToTalk = this.pushToTalkSwitch.checked;
	this.dispatchEvent(new CustomEvent('pushToTalkchange', {
	    detail: this.pushToTalk }));
    }

  _updateMuteButtonState() {
    this.muteButton.classList.toggle('muted', this.muted);
    this.muteButton.classList.toggle('talking', !this.muted && this.pushToTalk && this.playbackActive);
  }
    
    
  setPlaybackActive(active) {
    this.playbackActive = active;
    if (this.playbackActive) {
	this._previousPushToTalkState = this.pushToTalk;
	this.pushToTalk = true;
	this.pushToTalkSwitch.checked = true;
	this.pushToTalkSwitch.disabled = true;
    } else {
	this.pushToTalk = this._previousPushToTalkState;
	this.pushToTalkSwitch.checked = this.pushToTalk;
	this.pushToTalkSwitch.disabled = false;
    }
      this._updateMuteButtonState();
    }
}

customElements.define('mute-button', MuteButton);

```

```js peer-connection.js
class PeerConnection extends EventTarget {
    constructor(channelId, peerInputNode, peerOutputNode) {
	super();
	this.channelId = channelId;
	// Audio coming from the other peer to us
	this.peerInputNode = peerInputNode;

	// Audio we are sending to the other peer
	this.peerOutputNode = peerOutputNode;
	
	this.peerId = null; // Initialize peerId as null
	this.peer = null;
	this.conn = null;
	this.otherId = undefined;
	this.onDataReceived = null;
	this.onConnectionError = null;
	this.onConnectionClose = null;

	this._initialize(this.channelId);

	this.connectionResolution = null;
    }

    // Resolves when peer.conn is no longer null.
    async waitForConnection() {
        return new Promise(resolve => {
            if (this.conn) {
                resolve();
                return;
            } else {
		this.connectionResolution = resolve;
	    }
        });
    }

    connect(otherPeerId) {
	console.log('Connecting to peer...');
	if (this.conn) {
	    this.conn.close();
	}
	this.conn = this.peer.connect(otherPeerId);
	this._addConnHandlers();
    }
    
    sendMessage(message) {
	console.log(`Sending to ${this.conn.peer}`);
	this.conn.send(message);
    }
    
    async call(audioCtx, outgoingStreamDestination) {
	return new Promise((resolve, reject) => {
   	    const call = this.peer.call(this.otherId, outgoingStreamDestination.stream);
	    call.on('error', (err) => { 
		console.log(`Call error: ${err.message}`);
	    });
	    call.on('stream', (incomingStream) => {
		console.log('Hack is here.');
		// Ungodly hack to actually get the audio to flow
		const a = new Audio();
		a.muted = true;
		a.srcObject = incomingStream;
		a.addEventListener('canplaythrough', () => {
		    console.log('ready to flow'); });
		// End ungodly hack.
		console.log('Call stream');
		resolve(audioCtx.createMediaStreamSource(incomingStream));
	    });
	});
    }

    _addConnHandlers() {
	this.conn.on('data', (data) => {
	    console.log('Data reached Peer Connection');
	    console.log(data);
	    this.dispatchEvent(new CustomEvent('remoteDataReceived',
					       {detail: data}));
	});

	this.conn.on('close', () => console.log('Connection closed'));
	this.conn.on('error', (err) => console.log('Connection error: ', err));
    }
    
    
    _initialize(channelId) {
	// Ensure that peerId is set properly
	this.peer = new Peer(channelId);
	this.peer.on('open', this._onPeerOpen.bind(this));
	this.peer.on('connection', this._onPeerConnection.bind(this));
	this.peer.on('disconnected', this._onPeerDisconnected.bind(this));
	this.peer.on('close', this._onPeerClose.bind(this));
	this.peer.on('error', this._onPeerError.bind(this));
	this.peer.on('call', this._onPeerCall.bind(this));
	console.log('Initialization complete.');
    }

    async _onPeerOpen(id) {
	console.log(`Peer open: ${id}`);
	this.peerId = id; // Set peerId when the peer is opened
	if (this.channelId === this.peerId) {
	    console.log('I am server');
	    this.otherId = id;
	} else {
	    console.log('I am client');
	    this.otherId = this.channelId;
	    await this._join();
	}
	if (this.connectionResolution) {
	    console.log('Resolving connection waiter.');
	    this.connectionResolution();
	}
    }

    _onPeerConnection(c) {
	console.log(`Peer connection. Other: ${c.peer}`);
	this.otherId = c.peer;
	this.conn = c;
	this._addConnHandlers();
    }

    _onPeerDisconnected() {
	console.log('Peer disconnected');
    }

    _onPeerClose() {
	console.log('Peer close');
    }

    _onPeerError(err) {
	console.log(`Peer error`);
	console.log(err);
	if (err.message === `ID "${this.channelId}" is taken`) {
	    // Handle error logic (e.g., re-initialize or retry connection)
	    this._initialize(null);
	}
    }

    _onPeerCall(mediaConnection) {
	console.log(`Peer call from ${mediaConnection.peer}`);
	if (mediaConnection.peer == this.peer.id) {
	    console.log('Self call.  Ignore.');
	}
	const audioCtx = this.peerOutputNode.context;
	const outgoingStream =
	      audioCtx.createMediaStreamDestination();
	this.peerOutputNode.connect(outgoingStream);

	mediaConnection.answer(outgoingStream.stream);
	mediaConnection.on(
	    'stream',
	    (incomingStream) => this._handleIncomingStream(incomingStream));
    }

    _handleIncomingStream(incomingStream) {
	console.log('Stream Received');
	// Ideally, we want to disconnect anything coming into the
	// peerInputNode
	//if (this.peerInputNode) {
	//    this.peerInputNode.disconnect();
	//}
	console.log('Hack is here.');
	// Ungodly hack to actually get the audio to flow
	const a = new Audio();
	a.muted = true;
	a.srcObject = incomingStream;
	a.addEventListener('canplaythrough', () => {
	    console.log('ready to flow'); });
	
	// Properly handle stream and create media source node
	const audioCtx = this.peerInputNode.context;
	const peerInputStream = audioCtx.createMediaStreamSource(
	    incomingStream);
	peerInputStream.connect(this.peerInputNode);
    }

    async _join() {
	console.log('join');
	if (this.conn) {
	    this.conn.close();
	}
	this.conn = this.peer.connect(this.otherId);
	this._addConnHandlers();

	const audioCtx = this.peerOutputNode.context;
	const peerOutputStream = audioCtx.createMediaStreamDestination();
	this.peerOutputNode.connect(peerOutputStream);

	console.log(`Calling ${this.otherId}`);
	const mediaConnection = this.peer.call(
	    this.otherId, peerOutputStream.stream);
	mediaConnection.on('stream', (incomingStream) => {
	    console.log('Hack is here.');
	    // Ungodly hack to actually get the audio to flow
	    const a = new Audio();
	    a.muted = true;
	    a.srcObject = incomingStream;
	    a.addEventListener('canplaythrough', () => {
		console.log('ready to flow'); });
	    // End ungodly hack.
	    console.log('Got callee stream.');
	    const peerSourceStream =
		  audioCtx.createMediaStreamSource(incomingStream);
	    peerSourceStream.connect(this.peerInputNode);
	});
    }
    
}

```

```js worklet-recorder.js
class WorkletRecorder extends AudioWorkletProcessor {
    first = true;

    process(inputs) {
      if (inputs.length == 0) { return; }
      const channels = inputs[0];
      if (channels.length == 0) { return; }
      const samples = channels[0];
      // Caller expects monophonic data, so only return the first channel.
      this.port.postMessage({ 
        timestamp: currentTime,
        frame: currentFrame,
        samples: samples, 
      });
      return true;
    }
}

registerProcessor('worklet-recorder', WorkletRecorder);
```

```md readme.md
# Product Requirements Document: Collaborative Music Workspace

Connecting musicians and empowering their creativity.

## 1. Introduction

This document outlines the requirements for a collaborative music
workspace application. The application aims to provide musicians with
a platform to create, share, and refine musical ideas in real-time,
regardless of their physical location.


## 2. Goals

* Enable real-time musical collaboration between two users.

* Provide tools for sharing and developing musical ideas, including
    lyrics, chords, and audio recordings.

* Offer high-quality audio transmission for remote collaboration and
    songwriting sessions.

* Maintain a user-friendly and intuitive interface.

## 3. Target Audience

* Musicians (instrumentalists, vocalists, songwriters, composers).

* Music educators and students.

* Songwriting partners.

* Music producers

## 4. Features

### 4.1 Core Features

* **Peer-to-Peer Audio Connection:**

    * Establish and maintain low-latency audio connections with no noise
    reduction, compression, or other effects that are ineffective for
    music collaboration.
    
    * Support selection of audio input and output devices.
    
    * Provide individual gain control for monitoring and controlling outgoing
        and incoming signals.
    
* **Shared Scratch Pad:**

    * Real-time collaborative text editor.
    
    * Specific formatting options for chords and lyric lines.
        
* **Audio Recording & Sharing:**

    * Ability to record audio snippets locally.

    * Metronome with count-in options
    
    * Audio snippets are immediately shared with other participants
    
    * Playback controls for shared audio.
    
    * Visual representation of audio (e.g. waveform)

    * Simple arrangement of audio with lyrics

    * Shared BPM, measures per line, "tape rate" configuration


### 4.2 Future Enhancements (Out of Scope for Initial Release)

* Instrument tuner.

*   Advanced audio effects processing.

*   Integration with digital audio workstations (DAWs).

*   Video conferencing.

## 5. Technical Requirements

* **Platform:** Web-based application (cross-platform compatibility).

* **Technology Stack:** JavaScript, HTML, CSS, Web Audio API, WebRTC,
      IndexedDB.

* **Performance:** High quality audio recording and transmission is
    critical. Near immediate synchronization of song edits are
    essential.

* **Scalability:** The system should be able to handle two concurent
    users and sixteen simultaneous audio tracks.

* **Security:** Secure peer-to-peer connection and data transmission.

##6. User Interface (UI) and User Experience (UX) - Detailed MVP Design

The core goal is to facilitate real-time musical collaboration. The UI/UX should be simple, functional, and not get in the way of the creative process.

###6.1. Overall Layout:

*   **Split Screen:** The interface will be divided into two main areas:

    * **Shared Workspace:** The main area where the shared text
          editor, recorded audio snippets, metronome, and other
          collaborative tools are located.
    
    * **Local Control Panel:** A top bar that
          provides controls for audio settings, input/output
          selection, gain adjustment, and user-specific controls.
    
* **Clean Design:** The UI should avoid unnecessary visual
      clutter. Use clear icons and simple typography.

* **Responsive Design:** The layout should adapt to different screen
      sizes (desktop, tablets).

###6.2. Shared Workspace:

* **Real-time Text Editor:** A large, editable text area where users
    can write lyrics, chord progressions, and notes.
    
    * Real-time updates: When one user types, the changes should
        appear immediately on the other user's screen.
    
    *   Basic Formatting:
    
        *   Simple markup for chords (e.g., `[C]`, `[Am]`) to be displayed differently.
	
        *   Clear distinction between lyric lines and other notations.
	
*   **Audio Snippets:**

    * Audio snippets are displayed directly below or above the lyrics
        they correspond to.
    
    *   Each snippet will have:
    
        *   A waveform display for visual representation.
	
        *   The ability to be dragged and dropped for simple arrangement.
	
        *   Visual alignment of audio to beats and bars (grid-like).
	
*   **Metronome & Tempo:**

    *   A simple start/stop control for the metronome.
    
    *   Display for the current tempo (BPM).
    
    *   Input field to change BPM.
    
    *   Count-in option.
    
*   **Track Settings**

    *  Number of measures in a line
    
    *  "Tape speed"

###6.3. Local Control Panel:

*   **Audio Input/Output:**

    * Dropdown menus or radio buttons to select audio input and output
        devices.
    
    * Clear labels indicating the selected input and output devices.
    
* **Gain Controls:**

    * Individual sliders for adjusting the local input gain, the gain
        of audio being sent to the peer, and the gain of audio
        received from the peer.
    
* **Push to Talk:**

    When musician 1 starts playback, musician 2 can hear it.  Musician
    2 is muted unless they hold a button to talk.  This prevents
    musician 2 from transmitting their playing back to musician 1.
    Musician 1 would hear this with a significant delay which would
    make it difficult for musician 1 to play.  When muted, a musician
    can record.
    
* **Recording Controls:**

    * A prominent record button.
    
    * A visual indicator to show that recording is in progress.
    
    * The recording will be added to the "Audio Snippet Area".

###6.4. User Experience (UX) Principles:

* **Real-Time Feedback:** Provide visual cues for all actions, e.g.,
      when audio is playing, when recording is in progress, when a
      connection is made.

* **Intuitive Controls:** Make the controls easily accessible and
      understandable without requiring a tutorial.

* **Minimalist Approach:** Avoid unnecessary UI elements and
      animations. Focus on whatâ€™s essential for real-time
      collaboration.

* **Low Latency:** Strive for the lowest possible latency between
      actions and their effects.

* **Clear Communication:** Provide clear messaging for status updates,
      errors, and other important information.

###6.5. Workflow Example:

1.  **Setup:**

* Both users open the web application and a peer-to-peer connection is
    automatically established.
    
    * Both users select their audio input/output devices and adjust
        gain levels.

2.  **Songwriting:**

    * One user starts typing lyrics and chords in the shared text
        editor. The other user sees the changes in real-time.
    
    * One user sets the tempo

3.  **Recording & Sharing:**

    * One user starts recording.  The metronome clicks, and the other
    user can hear the metronome and what the first user is playing.
    
    * The recorded snippet appears as a waveform in the shared audio
        area.

    * Either user can now play back the recorded audio.

4.  **Refining:**

    * The users drag the audio snippets and arrange them to create a
       basic song structure.
    
    * The users work together to refine lyrics, timing, and tempo.

**In Summary:**

The MVP should prioritize providing a simple, efficient, and real-time
platform for musicians to collaborate. The UI/UX design will focus on
these key elements:

*   Real-time text editor with chord notation.

*   Simple audio recording and sharing with waveform display.

*   Local gain adjustment and audio device selection.

*   Metronome controls.

*   A clear "push to talk" feature.

This will allow musicians to start creating, sharing, and iterating on
ideas with minimal friction.

## 7. Release Criteria

* All core features implemented and tested.

* Stable and reliable audio connections.

* User-friendly interface with clear instructions.

* Basic error handling and informative messages.

## 8. Future Considerations

* Monetization strategy (e.g., subscription, premium features).

* Community features (e.g., public jam sessions, user profiles).

* Mobile application development.

```

You are working with a professional software developer.  You don't need to
explain the code you produce.  Please prefer short answers to longer ones.
For small changes, describing the change with a few lines of code is preferred
over rewriting the entire project.
When significant changes are required to a file, present the entire file.
Sometimes you will be asked for design advice.  Please provide the advice without
producing any code.
Prefer writing JavaScript classes to "naked" functions.
