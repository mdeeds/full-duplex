```css #style.css#
/* style.css */

body {
  font-family: sans-serif;
  background-color: #FAFAFA;
  color: #333;
  margin: 0;
  padding: 0;
  line-height: 1.6;
}

#audioConfig,
#peerStatus,
#gainController,
#recordingControls,
#audioSnippets {
  max-width: 700px;
  margin: 10px auto; /* Reduced margin */
  padding: 15px; /* Reduced padding */
  background-color: #fff;
  border-radius: 8px;
  box-shadow: 0 0 10px rgba(0, 0, 0, 0.05); /* Adjusted shadow */
}

h1, h2 {
    color: #B19CD9;
  font-weight: 600;
  margin-top: 0;
}

label {
  display: block;
  margin-bottom: 3px; /* Reduced margin */
  color: #555;
  font-weight: 500;
}

select,
input[type="range"] {
  width: 300px;
  padding: 8px; /* Reduced padding */
  margin-bottom: 10px; /* Reduced margin */
  border: 1px solid #ddd;
  border-radius: 6px;
  box-sizing: border-box;
  display: block;
}

button {
    background-color: #B19CD9;
  color: white;
  padding: 4px 7px;
  border: solid 1px #512DA8;
  border-radius: 4px;
  cursor: pointer;
  transition: background-color 0.3s ease;
}

button:hover {
  background-color: #512DA8;
}

.vu-meter-container {
  margin-bottom: 10px; /* Reduced margin */
}

.vu-meter-label {
  display: inline-block;
  margin-right: 8px; /* Reduced margin */
  color: #777;
  font-size: 13px;
}

.vu-meter {
  width: 100%;
  height: 10px; /* Reduced height */
  background-color: #eee;
  border-radius: 5px; /* Reduced border radius */
  overflow: hidden;
}

.vu-meter-bar {
  height: 100%;
  background-color: #4FC3F7;
  width: 0;
  transition: width 0.1s ease;
}

/* LED Styles */
.red-on {
  background-color: #E57373; /* Darker Red */
  box-shadow: 0 0 5px #E57373; /* Glow effect */
}

.red-off {
  background-color: #F44336; /* Slightly desaturated */
}

.yellow-on {
  background-color: #FFB74D; /* Darker Yellow */
  box-shadow: 0 0 5px #FFB74D; /* Glow effect */
}

.yellow-off {
  background-color: #FFC107; /* Slightly desaturated */
}

.green-on {
  background-color: #81C784; /* Darker Green */
  box-shadow: 0 0 5px #81C784; /* Glow effect */
}

.green-off {
  background-color: #4CAF50; /* Slightly desaturated */
}

/* Reduced spacing */
#audioConfig > *,
#peerStatus > *,
#gainController > *,
#recordingControls > *,
#audioSnippets > * {
  margin-bottom: 10px; /* Reduced margin */
}

/* Add to your existing style.css */

#routingControls {
  background-color: #f9f9f9;
  padding: 15px;
  border-radius: 8px;
  margin-bottom: 10px;
}

#routingControls h2 {
  font-size: 1.2em;
  margin-top: 0;
  margin-bottom: 10px;
}

.control-group {
  margin-bottom: 10px;
  display: flex;
  align-items: center;
}

.control-group label {
  margin-right: 10px;
  width: 150px; /* Adjust width as needed */
  text-align: right;
}

/* Toggle Switch Styles */
.toggle-switch {
  display: inline-flex;
  align-items: center;
  background-color: #ddd;
  border-radius: 5px;
  overflow: hidden;
}

.toggle-switch label {
  padding: 8px 12px;
  text-align: center;
  cursor: pointer;
  background-color: transparent;
  color: #555;
  margin: 0;
  width: 75px; /* Adjust width as needed */
}

.toggle-switch input[type="radio"] {
  display: none;
}

.toggle-switch input[type="radio"]:checked + label {
  background-color: #B19CD9; /* Lavender Accent */
  color: white;
}

/* Switch Styles (for Local Mic Monitor) */
.switch {
  position: relative;
  display: inline-block;
  width: 40px;
  height: 28px;
}

.switch input {
  opacity: 0;
  width: 0;
  height: 0;
}

.slider {
  position: absolute;
  cursor: pointer;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background-color: #ccc;
  transition: .4s;
  border-radius: 34px;
}

.slider:before {
  position: absolute;
  content: "";
  height: 20px;
  width: 20px;
  left: 4px;
  bottom: 4px;
  background-color: white;
  transition: .4s;
  border-radius: 50%;
}

input:checked + .slider {
  background-color: #B19CD9; /* Lavender Accent */
}

input:focus + .slider {
  box-shadow: 0 0 1px #B19CD9;
}

input + .slider {
  width: 60px;
}

input:checked + .slider:before {
  transform: translateX(32px);
}

/* Rounded sliders */
.slider.round {
  border-radius: 34px;
}

.slider.round:before {
  border-radius: 50%;
}

```

```css style.css
/* style.css */

body {
  font-family: sans-serif;
  background-color: #FAFAFA;
  color: #333;
  margin: 0;
  padding: 0;
  line-height: 1.6;
}

.mainSection {
  max-width: 700px;
  margin: 10px auto;
  padding: 15px;
  background-color: #fff;
  border-radius: 8px;
  box-shadow: 0 0 10px rgba(0, 0, 0, 0.05);
}

#audioConfig,
#peerStatus,
#gainController,
#recordingControls,
#audioSnippets {
}

#audioConfig {
    display: flex;
    flex-direction: row;
}

#localIO,
#dawIO {
    flex: 1; /* Distribute space equally between the two */
    margin-right: 10px; /* Add some spacing between the two */
}

h1, h2 {
    color: #B19CD9;
  font-weight: 600;
  margin-top: 0;
}

label {
  display: block;
  margin-bottom: 3px; /* Reduced margin */
  color: #555;
  font-weight: 500;
}

select,
input[type="range"] {
  width: 300px;
  padding: 8px; /* Reduced padding */
  margin-bottom: 10px; /* Reduced margin */
  border: 1px solid #ddd;
  border-radius: 6px;
  box-sizing: border-box;
  display: block;
}

button {
    background-color: #B19CD9;
  color: white;
  padding: 4px 7px;
  border: solid 1px #512DA8;
  border-radius: 4px;
  cursor: pointer;
  transition: background-color 0.3s ease;
}

button:hover {
  background-color: #512DA8;
}

.vu-meter-container {
  margin-bottom: 10px; /* Reduced margin */
}

.vu-meter-label {
  display: inline-block;
  margin-right: 8px; /* Reduced margin */
  color: #777;
  font-size: 13px;
}

.vu-meter {
  width: 100%;
  height: 10px; /* Reduced height */
  background-color: #eee;
  border-radius: 5px; /* Reduced border radius */
  overflow: hidden;
}

.vu-meter-bar {
  height: 100%;
  background-color: #4FC3F7;
  width: 0;
  transition: width 0.1s ease;
}

/* LED Styles */
.red-on {
  background-color: #E57373; /* Darker Red */
  box-shadow: 0 0 5px #E57373; /* Glow effect */
}

.red-off {
  background-color: #F44336; /* Slightly desaturated */
}

.yellow-on {
  background-color: #FFB74D; /* Darker Yellow */
  box-shadow: 0 0 5px #FFB74D; /* Glow effect */
}

.yellow-off {
  background-color: #FFC107; /* Slightly desaturated */
}

.green-on {
  background-color: #81C784; /* Darker Green */
  box-shadow: 0 0 5px #81C784; /* Glow effect */
}

.green-off {
  background-color: #4CAF50; /* Slightly desaturated */
}

/* Reduced spacing */
#audioConfig > *,
#peerStatus > *,
#gainController > *,
#recordingControls > *,
#audioSnippets > * {
  margin-bottom: 10px; /* Reduced margin */
}

/* Add to your existing style.css */

.control-group {
  margin-bottom: 10px;
  display: flex;
  align-items: center;
}

.control-group label {
  margin-right: 10px;
  width: 150px; /* Adjust width as needed */
  text-align: right;
}

/* Toggle Switch Styles */
.toggle-switch {
  display: inline-flex;
  align-items: center;
  background-color: #ddd;
  border-radius: 5px;
  overflow: hidden;
}

.toggle-switch label {
  padding: 8px 12px;
  text-align: center;
  cursor: pointer;
  background-color: transparent;
  color: #555;
  margin: 0;
  width: 75px; /* Adjust width as needed */
}

.toggle-switch input[type="radio"] {
  display: none;
}

.toggle-switch input[type="radio"]:checked + label {
  background-color: #B19CD9; /* Lavender Accent */
  color: white;
}

/* Switch Styles (for Local Mic Monitor) */
.switch {
  position: relative;
  display: inline-block;
  width: 40px;
  height: 28px;
}

.switch input {
  opacity: 0;
  width: 0;
  height: 0;
}

.slider {
  position: absolute;
  cursor: pointer;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background-color: #ccc;
  transition: .4s;
  border-radius: 34px;
}

.slider:before {
  position: absolute;
  content: "";
  height: 20px;
  width: 20px;
  left: 4px;
  bottom: 4px;
  background-color: white;
  transition: .4s;
  border-radius: 50%;
}

input:checked + .slider {
  background-color: #B19CD9; /* Lavender Accent */
}

input:focus + .slider {
  box-shadow: 0 0 1px #B19CD9;
}

input + .slider {
  width: 60px;
}

input:checked + .slider:before {
  transform: translateX(32px);
}

/* Rounded sliders */
.slider.round {
  border-radius: 34px;
}

.slider.round:before {
  border-radius: 50%;
}

```

```css style.css~
/* style.css */

body {
  font-family: sans-serif;
  background-color: #F0F0F0; /* Light Gray Background */
  color: #333; /* Dark Gray Text */
  margin: 0;
  padding: 0;
}

#audioConfig,
#peerStatus,
#gainController,
#recordingControls,
#audioSnippets {
  margin: 20px;
  padding: 20px;
  background-color: #fff; /* White panels */
  border-radius: 8px;
  box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
}

/* Typography */
h1, h2 {
  color: #B19CD9; /* Desaturated Lavender Headings */
}

label {
  display: block;
  margin-bottom: 5px;
  color: #555;
}

/* Form Elements */
select,
input[type="range"] {
  width: 100%;
  padding: 8px;
  margin-bottom: 10px;
  border: 1px solid #ccc;
  border-radius: 4px;
  box-sizing: border-box;
}

button {
  background-color: #B19CD9; /* Desaturated Lavender Buttons */
  color: white;
  padding: 10px 15px;
  border: none;
  border-radius: 4px;
  cursor: pointer;
  transition: background-color 0.3s ease;
}

button:hover {
  background-color: #9575CD; /* Darker Lavender on Hover */
}

/* VU Meter */
.vu-meter-container {
  margin-bottom: 10px;
}

.vu-meter-label {
  display: inline-block;
  margin-right: 5px;
  color: #777;
}

.vu-meter {
  width: 100%;
  height: 10px;
  background-color: #ddd;
  border-radius: 4px;
  overflow: hidden;
}

.vu-meter-bar {
  height: 100%;
  background-color: #81D4FA; /* Light Blue VU Meter Bar */
  width: 0;
  transition: width 0.1s ease;
}

```

```html index.html
<!DOCTYPE html>
<html>
  <head>
    <title>Audio Device Selection</title>
    <link rel="stylesheet" href="style.css">
    <script src="https://unpkg.com/peerjs@1.5.4/dist/peerjs.min.js"></script>
    <script src="audio.js"></script>
    <script src="audio-device-selector.js"></script>
    <script src="indexed-db-map.js"></script>
    <script src="peer-connection.js"></script>
    <script src="index.js"></script>
  </head>
  <body onload="start()">
    <div>
      <button id="startButton">Start</button>
      <div id="io" class="mainSection">
	<h2>IO</h2>
	<div id="audioConfig">
	  <div id='localIO'></div>
	  <div id='dawIO'></div>
	</div>
      </div>
      <div id="routingControls" class=mainSection>
	<h2>Routing & Monitoring</h2>
	<div class="control-group">
	  <label for="dawSource">Send to DAW:</label>
	  <div class="toggle-switch" id="dawSource">
	    <input type="radio" id="dawSourceLocal"
		   name="dawSource" value="local" checked>
	    <label for="dawSourceLocal">Local Mic</label>
	    <input type="radio" id="dawSourcePeer"
		   name="dawSource" value="peer">
	    <label for="dawSourcePeer">Peer</label>
	  </div>
	</div>
	<div>
	  <div class="control-group">
	    <label for="localMonitor">Local Mic Monitor:</label>
	    <label class="switch">
	      <input type="checkbox" id="localMonitor">
	      <span class="slider round"></span>
	    </label>
	  </div>
	  
	  <div class="control-group">
	    <label for="localMonitor">Peer Monitor:</label>
	    <label class="switch">
	      <input type="checkbox" id="peerMonitor" checked=true>
	      <span class="slider round"></span>
	    </label>
	  </div>
	</div>
      </div>
      <div id='peerStatus' class='mainSection'></div>
      <div id='gainController' class="mainSection"></div>

      <div id='recordingControls' class="mainSection">
	<button id='recordButton'>Record</button>
      </div>
      <div id='audioSnippets' class="mainSection"></div>
  </body>
</html>

```

```html sync.html
<!DOCTYPE html>
<html>
  <head>
    <title>SyncedDBMap Demo</title>
    <script src="https://unpkg.com/peerjs@1.5.4/dist/peerjs.min.js"></script>
    <script src="indexed-db-map.js"></script>
    <script src="peer-connection.js"></script>
    <script src="mute-button.js"></script>
    <script>
      let syncedDBMap;

      async function startDemo() {
	  const startButton = document.getElementById('startButton');
	  startButton.remove();
	  // We create these  nodes but don't wire them up for this demo.
	  const audioCtx = new AudioContext();
	  const peerInputNode = audioCtx.createGain();
	  const peerOutputNode = audioCtx.createGain();
	  const div1 = document.getElementById('div1');

	  console.log('Creating peer connection.');
	  
	  const peerConnection = new PeerConnection(
	      'syncDemoConnectionId', peerInputNode, peerOutputNode);
	  
          syncedDBMap = new SyncedDBMap(
	      'syncDemoDB', peerConnection);

          syncedDBMap.localMap.addEventListener('dataChanged', (event) => {
	      console.log('dataChanged event from DB');
              div1.textContent = event.detail.value;
              document.getElementById('div2').textContent = event.detail.value;
          });

	  div1.addEventListener('input', updateContent);
      }

      async function updateContent() {
	  console.log('input event from HTML');
          const content = document.getElementById('div1').textContent;
	  console.log(`Content: ${content}`);
          await syncedDBMap.set('sharedContent', content);
      }
    </script>
  </head>
  <body>
    <button onclick="startDemo()" id='startButton'>Start Demo</button>
    <div>
      <h2>Div 1</h2>
      <div contenteditable='true' id="div1"></div>
    </div>
    <div>
      <h2>Div 2</h2>
      <div contenteditable='true' id="div2"></div>
    </div>
    <div>
      <mute-button id='myMute'></mute-button>
      </div>
  </body>
</html>

```

```js audio-device-selector.js
// Handles audio input and output selection
class AudioDeviceSelector {
    constructor(containerDiv, inputLabel, outputLabel, audioCtx) {
	this._audioCtx = audioCtx;
	this.containerDiv = containerDiv;
	this.inputLabel = inputLabel;
	this.outputLabel = outputLabel;
	this.inputDevices = [];
	this.outputDevices = [];

	this.currentOutputDeviceId = '';
	
	this.inputNode = audioCtx.createGain();
	this.outputNode = audioCtx.createGain();

	new VUMeter(this.inputNode, document.body, inputLabel);
	new VUMeter(this.outputNode, document.body, outputLabel);
	
	this._rawInputSourceNode;
    }

    async initialize() {
	await this.enumerateDevices();
	this.inputSelector(this.containerDiv);
	this.outputSelector(this.containerDiv);

	this.outputStream = this._audioCtx.createMediaStreamDestination();
	this.outputNode.connect(this.outputStream);

	this._outputContext = new AudioContext();
	this.outputSink = this._outputContext.createMediaStreamSource(
	    this.outputStream.stream);
	this.outputSink.connect(this._outputContext.destination);
    }
    
    async setAudioInput(deviceId) {
	if (!!this._rawInputSourceNode) {
	    this._rawInputSourceNode.disconnect();
	    this._rawInputSourceNode = null;
	}
	if (!deviceId) { return; }
	const stream = await navigator.mediaDevices.getUserMedia({
	    audio: {
		deviceId: deviceId,
		echoCancellation: false,
		noiseSuppression: false,
		autoGainControl: false,
		latencyHint: 'low',
	    },
	});
	this._rawInputSourceNode =
	      this._audioCtx.createMediaStreamSource(stream);

	// new VUMeter(this.rawInputSource, document.body);
	
	this._rawInputSourceNode.connect(this.inputNode);
	console.log(`Input device added: ${deviceId}`);
	return;  // Explicit return so that `await` works.
    }

    async setAudioOutput(deviceId) {
	if (!this._outputContext) {
	    console.error("AudioContext or localOutputNode not initialized.");
	    return;
	}

	if (!deviceId) {
	    this.outputSink.disconnect(this._outputContext.destination);
	} else {
	    this.outputSink.connect(this._outputContext.destination);
	}
	
	await this._outputContext.setSinkId(deviceId);
	return;  // Explicit return so that `await` works.
    }

    async enumerateDevices() {
	console.log('Scanning...');
	const devices = await navigator.mediaDevices.enumerateDevices();
	console.log('Enumerating...');
	const inputDevices = devices.filter(
	    device => device.kind === 'audioinput');
	const outputDevices = devices.filter(
	    device => device.kind === 'audiooutput');
	this.inputDevices = inputDevices;
	this.outputDevices = outputDevices;

	console.log(`Inputs: ${inputDevices.length};`);
	console.log(`Outputs: ${outputDevices.length}`);
    }

    inputSelector(div) {
	console.log('Adding input device selector');
	const inputList = document.createElement('span');
	inputList.innerHTML = this.inputLabel;
	div.appendChild(inputList);

	const select = document.createElement('select');
	select.name = 'inputDevice';
	select.id = 'inputDeviceSelect';
	inputList.appendChild(select);

	{
	    const option = document.createElement('option');
	    option.value = '';
	    option.text = 'None';
	    select.appendChild(option);
	}
	
	for (const device of this.inputDevices) {
	    const option = document.createElement('option');
	    option.value = device.deviceId;
	    option.text = device.label || device.deviceId;
	    select.appendChild(option);
	}

	select.addEventListener('change', async() => {
	    console.log(`Value: ${select.value}`);
	    await this.setAudioInput(select.value);
	});
    }

    outputSelector(div) {
	console.log('Adding output device selector');
	const outputList = document.createElement('span');
	outputList.innerHTML = this.outputLabel
	div.appendChild(outputList);

	const select = document.createElement('select');
	select.name = 'outputDevice';
	select.id = 'outputDeviceSelect';
	outputList.appendChild(select);

	{
	    const option = document.createElement('option');
	    option.value = '';
	    option.text = 'None';
	    select.appendChild(option);
	}
	
	for (const device of this.outputDevices) {
	    const option = document.createElement('option');
	    option.value = device.deviceId;
	    option.text = device.label || device.deviceId;
	    select.appendChild(option);
	}

	select.addEventListener('change', async() => {
	    console.log(`Value: ${select.value}`);
	    await this.setAudioOutput(select.value);
	});
    }
}

```

```js audio.js
class AudioManager extends EventTarget {
    constructor() {
	super();
	this.audioCtx = null;
	this.localInputNode = null;

	this.isRecording = false;
	this.recordingBuffer = null;
	this.samplesRecorded = 0;

	this.localSelector = undefined;
	this.dawSelector = undefined;
    }
    
    ctx() {
	return this.audioCtx;
    }

    async initialize() {
	this.audioCtx = new AudioContext();
	const recordButton = document.getElementById('recordButton');
	recordButton.addEventListener(
	    'click', (event) => { this._toggleRecording(event); });

	console.log('Creating input selectors.');
	this.localSelector = new AudioDeviceSelector(
	    document.getElementById('localIO'),
	    "Audio Source (mic)", "Audio destination (headphones)",
	    this.audioCtx);
	await this.localSelector.initialize();

	// Create a worklet recorder and add it to the graph.
	await this.audioCtx.audioWorklet.addModule('worklet-recorder.js');
	this.workletRecorderNode = new AudioWorkletNode(
	    this.audioCtx, 'worklet-recorder');
	this.workletRecorderNode.port.onmessage = (event) => {
	    this._processRecordingData(event.data);
	}
	this.localSelector.inputNode.connect(this.workletRecorderNode);
	
	this.dawSelector = new AudioDeviceSelector(
	    document.getElementById('dawIO'),
	    "DAW return", "DAW send", this.audioCtx);
	await this.dawSelector.initialize();
    }

    _processRecordingData(data) {
	if (!this.isRecording) {
	    return;
	}
	if (this.samplesRecorded + data.samples.length >
	    this.recordingBuffer.length) {
	    // Add a second to the recording buffer.
	    const newBuffer = new Float32Array(this.recordingBuffer.length +
					       this.audioCtx.sampleRate);
	    newBuffer.set(this.recordingBuffer);
	    this.recordingBuffer = newBuffer;
	}
	this.recordingBuffer.set(data.samples, this.samplesRecorded);
	this.samplesRecorded += data.samples.length;
    }
    
    _toggleRecording(event) {
	if (this.isRecording) {
	    event.target.innerHTML = 'Record';
	    this.dispatchEvent(new CustomEvent('recordingAvailable', {
		detail: {
		    buffer: this.recordingBuffer,
		    numSamples: this.samplesRecorded,
		    seconds: (this.samplesRecorded / this.audioCtx.sampleRate)
		}}));
	    this.recordingBuffer = null;
	    this.samplesRecorded = 0;
	} else {
	    event.target.innerHTML = 'Stop';
	    this.recordingBuffer = new Float32Array(this.audioCtx.sampleRate);
	}
	this.isRecording = !this.isRecording;
    }
}

class GainController {
    constructor(inputNode, outputNode, inputPeerNode, outputPeerNode,
		sendDawNode, returnDawNode) {
        this.inputNode = inputNode;
        this.outputNode = outputNode;
        this.inputPeerNode = inputPeerNode;
        this.outputPeerNode = outputPeerNode;
	this.sendDawNode = sendDawNode;
	this.returnDawNode = returnDawNode;
	
        this.audioContext = inputNode.context;

	// First wire up the managed connections
        const inputToOutputGain = this.audioContext.createGain();
	this.inputNode.connect(inputToOutputGain);
	inputToOutputGain.connect(this.outputNode);
	this._wireCheckbox(document.getElementById('localMonitor'),
		     inputToOutputGain);

	const inputToDawSend = this.audioContext.createGain();
	this.inputNode.connect(inputToDawSend);
	inputToDawSend.connect(this.sendDawNode);
	const peerToDawSend = this.audioContext.createGain();
	this.inputPeerNode.connect(peerToDawSend);
	peerToDawSend.connect(this.sendDawNode);
	this._wireToggle(document.getElementById('dawSource'),
			{peer: peerToDawSend,
			 local: inputToDawSend});

	const peerToOutput = this.audioContext.createGain();
	this.inputPeerNode.connect(peerToOutput);
	peerToOutput.connect(this.outputNode);
	this._wireCheckbox(document.getElementById('peerMonitor'),
			  peerToOutput);

	// Wire all static connections
	this.inputNode.connect(this.outputPeerNode);
	this.returnDawNode.connect(this.outputPeerNode);
	this.returnDawNode.connect(this.outputNode);
    }

    dbToGain(x) {
        return x <= -30 ?
	    0 : Math.pow(10, x / 20);
    }
    
    _createSlider(labelText, gainNode, initialValue = 0) {
        const container = document.createElement('div');
        const label = document.createElement('label');
        label.textContent = labelText;
        const slider = document.createElement('input');
        slider.type = 'range';
        slider.min = -30;
        slider.max = 10;
        slider.step = 1;
        slider.value = initialValue;
	gainNode.gain.value = this.dbToGain(initialValue);
	
        slider.addEventListener('input', () => {
            const gainValue = parseFloat(slider.value);
            gainNode.gain.value = this.dbToGain(gainValue);
        });

        container.appendChild(label);
        container.appendChild(slider);
        this.parentDiv.appendChild(container);
    }

    _wireToggle(container, gains) {
	container.addEventListener('change', (event) => {
	    for (const key in gains) {
		gains[key].gain.value = (key === event.target.value) ? 1 : 0;
	    }
	});
    }

    _wireCheckbox(checkbox, gainNode) {
	checkbox.addEventListener('change', (event) => {
	    gainNode.gain.value = event.target.checked ? 1 : 0;
	});
    }
}

class VUMeter {
    constructor(audioNode, parentDiv, labelText) {
        this.audioNode = audioNode;
        this.parentDiv = parentDiv;
        this._analyser = audioNode.context.createAnalyser();
        this.audioNode.connect(this._analyser);
        this._analyser.fftSize = 2048;
        this.dataArray = new Uint8Array(this._analyser.frequencyBinCount);

        this.containerDiv = document.createElement('div');

        this.labelElement = document.createElement('span');
        this.labelElement.textContent = labelText + ': ';
        this.containerDiv.appendChild(this.labelElement);

        this.vuMeterElement = document.createElement('div');
        this.vuMeterElement.style.width = '0%';
        this.vuMeterElement.style.height = '10px';
        this.vuMeterElement.style.backgroundColor = 'green';
        this.containerDiv.appendChild(this.vuMeterElement);

        this.parentDiv.appendChild(this.containerDiv);

        this._tick = this._tick.bind(this);
        this._tick();
    }

    analyser() {
	return this._analyser;
    }

    _tick() {
        this._analyser.getByteFrequencyData(this.dataArray);
        let maxValue = 0;
        for (let i = 0; i < this.dataArray.length; i++) {
            maxValue = Math.max(maxValue, this.dataArray[i]);
        }
        this.vuMeterElement.style.width = `${0.1 + maxValue / 2.55}%`; // Scale to 0-100%
        requestAnimationFrame(this._tick);
    }
}

```

```js index.js
function createTestToneButton(outputNode) {
    const button = document.createElement('button');
    button.textContent = 'Play Test Tone';
    document.body.appendChild(button);
    const audioContext = outputNode.context;
    const oscillator = audioContext.createOscillator();
    const gainNode = audioContext.createGain();

    gainNode.gain.value = 0;
    
    oscillator.connect(gainNode);
    gainNode.connect(outputNode);
    // gainNode.connect(audioContext.destination);
    oscillator.start();
    
    button.addEventListener('click', () => {
        const startTime = audioContext.currentTime;
        const endTime = startTime + 1;
        gainNode.gain.linearRampToValueAtTime(0.2, startTime + 0.01);
        gainNode.gain.linearRampToValueAtTime(0.2, endTime - 0.01);
        gainNode.gain.linearRampToValueAtTime(0, endTime);
    });
}

function audioBufferToWav(float32Buffer, audioCtx) {
    const numberOfChannels = 1
    const sampleRate = audioCtx.sampleRate;
    const length = float32Buffer.length * numberOfChannels * 2;
    const buffer = new ArrayBuffer(44 + length);
    const view = new DataView(buffer);

    // RIFF identifier
    writeString(view, 0, 'RIFF');
    // RIFF chunk size
    view.setUint32(4, 36 + length, true);
    // RIFF type
    writeString(view, 8, 'WAVE');
    // Format chunk identifier
    writeString(view, 12, 'fmt ');
    // Format chunk size
    view.setUint32(16, 16, true);
    // Format code
    view.setUint16(20, 1, true);
    // Number of channels
    view.setUint16(22, numberOfChannels, true);
    // Sample rate
    view.setUint32(24, sampleRate, true);
    // Byte rate (sample rate * block align)
    view.setUint32(28, sampleRate * 2 * numberOfChannels, true);
    // Block align (channels * bytes per sample)
    view.setUint16(32, numberOfChannels * 2, true);
    // Bits per sample
    view.setUint16(34, 16, true);
    // Data chunk identifier
    writeString(view, 36, 'data');
    // Data chunk size
    view.setUint32(40, length, true);

    floatTo16BitPCM(view, 44, float32Buffer);
    
    return buffer;
}


function floatTo16BitPCM(output, offset, input) {
    for (let i = 0; i < input.length; i++, offset += 2) {
	const s = Math.max(-1, Math.min(1, input[i]));
	output.setInt16(offset, s < 0 ? s * 0x8000 : s * 0x7FFF, true);
    }
}

function writeString(view, offset, string) {
    for (let i = 0; i < string.length; i++) {
	view.setUint8(offset + i, string.charCodeAt(i));
    }
}

class AudioSnippet {
    constructor(key, buffer, numSamples, seconds, audioManager, containerDiv) {
	this.key = key;
	this.buffer = buffer;
	this.numSamples = numSamples;
	this.seconds = seconds;
	this.audioManager = audioManager;
	this.containerDiv = containerDiv;
	this.snippetDiv = document.createElement('div');
	this.snippetDiv.textContent =
	    `${Math.round(1000 * this.seconds)/1000}s`;
	this.snippetButton = document.createElement('button');
	this.snippetButton.innerHTML = "&#9654;";
	this.snippetDiv.appendChild(this.snippetButton);
	this.downloadButton = document.createElement('button');
	this.downloadButton.innerHTML = '\u2B73';
	this.snippetDiv.appendChild(this.downloadButton);
	this.containerDiv.appendChild(this.snippetDiv);

	this.snippetButton.addEventListener(
	    'click',
	    () => {
		this._play();
	    });
	this.downloadButton.addEventListener(
	    'click',
	    () => {
		this._download();
	    });
    }

    _play() {
	// Play the buffer.
	const audioCtx = this.audioManager.ctx();
	const source = audioCtx.createBufferSource();
	const audioBuffer = audioCtx.createBuffer(
	    1, this.buffer.length, audioCtx.sampleRate);
	audioBuffer.copyToChannel(this.buffer, 0);
	source.buffer = audioBuffer;
	source.connect(this.audioManager.localSelector.outputNode);
	source.start();
    }
    
    _download() {
	const audioCtx = this.audioManager.ctx();
	const wavData = audioBufferToWav(this.buffer, audioCtx);
	const blob = new Blob([wavData], { type: 'audio/wav' });
	const url = URL.createObjectURL(blob);
	const a = document.createElement('a');
	a.href = url;
	a.download = 'recording.wav';
	a.click();
	URL.revokeObjectURL(url);
    }
}

function _encodeFloat32Array(float32Array) {
    const buffer = float32Array.buffer;
    return new Uint8Array(buffer);
}

function _decodeFloat32Array(uint8Array) {
    const buffer = uint8Array.buffer;
    return new Float32Array(buffer);
}

function start() {
    console.log('Setting up start logic.');
    document.getElementById('startButton').addEventListener(
	'click', async (event) => {
	    console.log('Start clicked');
	    const audioDiv = document.getElementById('audioConfig');
	    event.target.remove();

	    const audioManager = new AudioManager();
	    await audioManager.initialize();
	    	    
	    // Create a couple of nodes we will use to manage the
	    // transient connections with our peer.
	    const peerInputNode = audioManager.ctx().createGain();
	    const peerOutputNode = audioManager.ctx().createGain();

	    createTestToneButton(audioManager.localSelector.outputNode);

	    const gainController = new GainController(
		audioManager.localSelector.inputNode,
		audioManager.localSelector.outputNode,
		peerInputNode, peerOutputNode,
		audioManager.dawSelector.outputNode,  // Send
		audioManager.dawSelector.inputNode);  // Return

	    // Attempt to establish the peer connection.
            const peerStatus = document.getElementById('peerStatus');
	    const peerConnection = new PeerConnection(
		"HelloTwinZ2", peerInputNode, peerOutputNode, peerStatus);
	    
	    peerConnection.addEventListener(
		'peerStreamEstablished',
		(event) => {
		    console.log('Peer stream established in index.js');
		});

	    const syncedDBMap =
		  new SyncedDBMap('audioSnippets', peerConnection);

	    const audioSnippetsDiv = document.getElementById('audioSnippets');
	    
	    syncedDBMap.localMap.addEventListener(
		'dataChanged',
		(event) => {
		    console.log('dataChanged event from DB');
		    const float32Buffer =
			  _decodeFloat32Array(event.detail.value.buffer);
		    new AudioSnippet(
			event.detail.key,
			float32Buffer,
			event.detail.value.numSamples,
			event.detail.value.seconds,
			audioManager,
			audioSnippetsDiv);
		});
	    
	    audioManager.addEventListener(
		'recordingAvailable',
		async (event) => {
		    console.log(`Recording available ${event.detail.seconds}s`);

		    const dbDetail = event.detail;
		    dbDetail.buffer = _encodeFloat32Array(dbDetail.buffer);
		    await syncedDBMap.set(
			Date.now(), {
			    ...dbDetail,
			});
		});
	});
}

```

```js indexed-db-map.js
class IndexedDBMap {
    constructor(databaseName) {
	this.databaseName = databaseName;
	this.dbPromise = this.openDatabase();
    }

    async openDatabase() {
	return new Promise((resolve, reject) => {
	    const request = indexedDB.open(this.databaseName, 1);

	    request.onupgradeneeded = (event) => {
		const db = event.target.result;
		if (!db.objectStoreNames.contains('map')) {
		    db.createObjectStore('map', { keyPath: 'key' });
		}
	    };

	    request.onsuccess = (event) => {
		resolve(event.target.result);
	    };

	    request.onerror = (event) => {
		reject(event.target.error);
	    };
	});
    }

    async get(key) {
	console.assert(!!key);
	const db = await this.dbPromise;
	const tx = db.transaction('map', 'readonly');
	const store = tx.objectStore('map');
	const request = store.get(key);

	return new Promise((resolve, reject) => {
	    request.onsuccess = (event) => {
		resolve(event.target.result?.value); 
	    };
	    request.onerror = (event) => {
		reject(event.target.error);
	    };
	});
    }
    
    async set(key, value, version) {
	// console.log(`IndexedDBMap set ${value}`);
        const db = await this.dbPromise;
	const tx = db.transaction('map', 'readwrite');
	const store = tx.objectStore('map');
	const request = store.put({ key, value, version });

	return new Promise((resolve, reject) => {
	    request.onsuccess = () => resolve();
	    request.onerror = (event) => reject(event.target.error);
	    tx.oncomplete = () => resolve(); 
	});
    }

    async contains(key) {
	const db = await this.dbPromise;
	const tx = db.transaction('map', 'readonly');
	const store = tx.objectStore('map');
	const request = store.get(key);

	return new Promise((resolve, reject) => {
	    request.onsuccess = (event) => {
		resolve(event.target.result !== undefined); 
	    };
	    request.onerror = (event) => {
		reject(event.target.error);
	    };
	});
    }
}

class ObservableIndexedDBMap extends EventTarget {
    constructor(databaseName) {
	super(); 
	this.map = new IndexedDBMap(databaseName); 
    }

    async get(key) {
	console.assert(!!key);
	return this.map.get(key);
    }

    _makeVersion() {
	return `${Date.now()}-${Math.random().toString(36).substring(2, 15)}`;
    }

    async set(key, value, version = undefined) {
	// console.log(`ObservableIndexedDBMap set ${value}`);
	if (!version) {
	    version = this._makeVersion();
	} else {
	    const currentValue = await this.get(key);
	    if (currentValue && currentValue.version === version) {
		// Nothing to do - we already have the latest version.
		return false;
	    }
	}
	await this.map.set(key, value, version);
	this.dispatchEvent(new CustomEvent('dataChanged', {
	    detail: { key, value, version } }));
	return true;
    }

    async contains(key) {
	return this.map.contains(key);
    }
}

class SyncedDBMap {
    constructor(databaseName, peerConnection) {
	this.localMap = new ObservableIndexedDBMap(databaseName);
	this.peerConnection = peerConnection;
	this._attachHandlers();
    }

    async _attachHandlers() {
	await this.peerConnection.waitForConnection();

	console.log('Peer connection established.');
	this.peerConnection.addEventListener('remoteDataReceived', (event) => {
	    // console.log('Data reached DB');
	    // console.log(event.detail);
	    
	    this._setInternal(
		event.detail.key, event.detail.value, event.detail.version);
	});
	console.log('Synchronization handlers attached.');
    }

    async get(key) {
	return this.localMap.get(key);
    }

    async set(key, value, version = undefined) {
	// console.log(`SyncedDBMap set ${value}`);
	await this._setInternal(key, value, version);
	this._sendUpdate(key, value, version);
    }

    async _setInternal(key, value, version = undefined) {
	this.localMap.set(key, value, version);
    }

    async contains(key) {
	return this.localMap.contains(key);
    }

    _sendUpdate(key, value, version) {
	// console.log(`send update ${value}`);
	if (this.peerConnection.conn && this.peerConnection.conn.open) {
	    this.peerConnection.sendMessage({
		type: 'db-sync',
		key: key,
		value: value,
		version: version,
		source: 'local',
	    });
	}
    }
}

```

```js mute-button.js
class MuteButton extends HTMLElement {
    constructor() {
        super();
        this.attachShadow({ mode: 'open' });
        this.muted = true;
        this.pushToTalk = false;
        this.playbackActive = false;
        this._previousPushToTalkState = false;

        this.shadowRoot.innerHTML = `
            <style>
            :host {
                display: inline-block;
            }
            .mute-container {
                display: flex;
                align-items: center;
            }
            .mute-button {
                background-color: #f0f0f0;
                border: 1px solid #ccc;
                padding: 10px 15px;
                cursor: pointer;
                border-radius: 5px;
                margin-right: 10px;
                user-select: none; /* Prevent text selection on click */
            }
            .mute-button.muted {
                background-color: #ddd;
            }
            .mute-button.talking {
                background-color: lightgreen;
            }
           .mute-button:disabled {
                opacity: 0.5;
                cursor: not-allowed;
            }
            .push-to-talk-switch {
                display: flex;
                align-items: center;
            }
            .push-to-talk-switch input[type="checkbox"] {
               opacity: 0;
               position: absolute;
               }
            .push-to-talk-switch label {
               cursor: pointer;
               padding: 5px;
            }
            .push-to-talk-switch label::before {
               content: '';
               display: inline-block;
               width: 20px;
               height: 10px;
               border: 2px solid #ccc;
               border-radius: 10px;
               background-color: #ccc;
               vertical-align: middle;
               margin-right: 5px;
            }
            .push-to-talk-switch input[type="checkbox"]:checked + label::before {
               background-color: lightgreen;
            }
           .push-to-talk-switch input[type="checkbox"]:checked + label::after {
                content: '';
                display: inline-block;
                width: 10px;
                height: 10px;
                border-radius: 50%;
                background-color: #fff;
                margin-left: 10px;
                position: relative;
                top: -2px;
           }
           .push-to-talk-switch input[type="checkbox"]:disabled + label {
                opacity: 0.5;
                cursor: not-allowed;
           }

            </style>
            <div class="mute-container">
                <div class="mute-button muted" tabindex="0">Mute</div>
                <div class="push-to-talk-switch">
                  <input type="checkbox" id="pushToTalkSwitch">
                  <label for="pushToTalkSwitch">Push to Talk</label>
                </div>
            </div>
        `;
	this.muteButton = this.shadowRoot.querySelector('.mute-button');
	this.pushToTalkSwitch = this.shadowRoot.querySelector('#pushToTalkSwitch');
        this.pushToTalkLabel = this.shadowRoot.querySelector('label[for="pushToTalkSwitch"]');
	this._attachEventListeners();
    }

  _attachEventListeners() {
    this.muteButton.addEventListener('click', this._handleMuteClick.bind(this));
    this.pushToTalkSwitch.addEventListener('change', this._handlePushToTalkChange.bind(this));
        this.muteButton.addEventListener('mousedown', this._handleMuteMouseDown.bind(this));
        this.muteButton.addEventListener('mouseup', this._handleMuteMouseUp.bind(this));
	// Handle keyboard accessibility.
	this.muteButton.addEventListener('keydown', (event) => {
	    if (event.code === 'Space' || event.code === 'Enter') {
		this._handleMuteClick();
	    }
	});
  }


    _handleMuteClick() {
        if (!this.playbackActive) {
            this.muted = !this.muted;
	    this._updateMuteButtonState();
            this.dispatchEvent(new CustomEvent('mutechange', { detail: this.muted }));
        }
    }

     _handleMuteMouseDown() {
      if (this.playbackActive && this.pushToTalk) {
          this.muted = false;
          this._updateMuteButtonState();
	  this.dispatchEvent(new CustomEvent('mutechange', { detail: this.muted }));
	  
      }
    }

    _handleMuteMouseUp() {
        if (this.playbackActive && this.pushToTalk) {
            this.muted = true;
            this._updateMuteButtonState();
	    this.dispatchEvent(new CustomEvent('mutechange', { detail: this.muted }));
       }
    }


    _handlePushToTalkChange() {
        this.pushToTalk = this.pushToTalkSwitch.checked;
	this.dispatchEvent(new CustomEvent('pushToTalkchange', {
	    detail: this.pushToTalk }));
    }

  _updateMuteButtonState() {
    this.muteButton.classList.toggle('muted', this.muted);
    this.muteButton.classList.toggle('talking', !this.muted && this.pushToTalk && this.playbackActive);
  }
    
    
  setPlaybackActive(active) {
    this.playbackActive = active;
    if (this.playbackActive) {
	this._previousPushToTalkState = this.pushToTalk;
	this.pushToTalk = true;
	this.pushToTalkSwitch.checked = true;
	this.pushToTalkSwitch.disabled = true;
    } else {
	this.pushToTalk = this._previousPushToTalkState;
	this.pushToTalkSwitch.checked = this.pushToTalk;
	this.pushToTalkSwitch.disabled = false;
    }
      this._updateMuteButtonState();
    }
}

customElements.define('mute-button', MuteButton);

```

```js peer-connection.js
// peer-connection.js
class PeerConnection extends EventTarget {
    constructor(channelId, peerInputNode, peerOutputNode, statusDiv) {
	super();
	this.channelId = channelId;
	// Audio coming from the other peer to us
	this.peerInputNode = peerInputNode;

	// Audio we are sending to the other peer
	this.peerOutputNode = peerOutputNode;
	
	this.peerId = null; // Initialize peerId as null
	this.peer = null;
	this.conn = null;
	this.otherId = undefined;
	this.onDataReceived = null;
	this.onConnectionError = null;
	this.onConnectionClose = null;
	this.statusDiv = statusDiv;

	this._initialize(this.channelId);

	this.connectionResolution = null;
    }

    // Resolves when peer.conn is no longer null.
    async waitForConnection() {
        return new Promise(resolve => {
            if (this.conn) {
                resolve();
                return;
            } else {
		this.connectionResolution = resolve;
	    }
        });
    }

    connect(otherPeerId) {
	this._updateStatus("Connecting...");
	console.log('Connecting to peer...');
	if (this.conn) {
	    this.conn.close();
	}
	this.conn = this.peer.connect(otherPeerId);
	this._addConnHandlers();
    }
    
    sendMessage(message) {
	console.log(`Sending to ${this.conn.peer}`);
	this.conn.send(message);
    }
    
    async call(audioCtx, outgoingStreamDestination) {
	return new Promise((resolve, reject) => {
   	    const call = this.peer.call(
		this.otherId, outgoingStreamDestination.stream);
	    call.on('error', (err) => { 
		console.log(`Call error: ${err.message}`);
		this._updateStatus(`Call error: ${err.message}`);
	    });
	    call.on('stream', (incomingStream) => {
		console.log('Hack is here.');
		// Ungodly hack to actually get the audio to flow
		const a = new Audio();
		a.muted = true;
		a.srcObject = incomingStream;
		a.addEventListener('canplaythrough', () => {
		    console.log('ready to flow'); });
		// End ungodly hack.
		console.log('Call stream');
		this._updateStatus("Call established.");
		resolve(audioCtx.createMediaStreamSource(incomingStream));
	    });
	});
    }

    _addConnHandlers() {
	this.conn.on('data', (data) => {
	    console.log('Connection data');
	    console.log(data);
	    this.dispatchEvent(new CustomEvent('remoteDataReceived',
					       {detail: data}));
	});

	this.conn.on('close', () => {
	    console.log('Connection closed');
	    this._updateStatus("Connection closed.");
	    // this._reset();
	});
	this.conn.on('error', (err) => {
	    console.log('Connection error: ', err);
	    this._updateStatus(`Connection error: ${err}`);
	});
    }

    async _reset() {
	console.log('Resetting peer connection.');
	this._updateStatus("Resetting connection...");
	if (this.conn) {
	    this.conn.close();
	    this.conn = null;
	}
	this.otherId = undefined;
	// Re-initialize the peer, which will create a new peer ID.
	this._initialize(this.channelId);
    }

    _updateStatus(status) {
	this.statusDiv.textContent = `Status: ${status}`;
    }
    
    
    _initialize(channelId) {
	this._updateStatus("Initializing...");
	// Ensure that peerId is set properly
	this._updateStatus("Initializing peer...");
	this.peer = new Peer(channelId);
	this.peer.on('open', this._onPeerOpen.bind(this));
	this.peer.on('connection', this._onPeerConnection.bind(this));
	this.peer.on('disconnected', this._onPeerDisconnected.bind(this));
	this.peer.on('close', this._onPeerClose.bind(this));
	this.peer.on('error', this._onPeerError.bind(this));
	this.peer.on('call', this._onPeerCall.bind(this));
	console.log('Initialization complete.');
    }

    async _onPeerOpen(id) {
	console.log(`Peer open: ${id}`);
	this.peerId = id; // Set peerId when the peer is opened
	this._updateStatus(`Peer ID: ${id}`);
	if (this.channelId === this.peerId) {
	    console.log('I am server');
	    this.otherId = id;
	    // The server doesn't try to join.
	} else {
	    console.log('I am client');
	    this.otherId = this.channelId;
	    await this._join();
	}
	if (this.connectionResolution) {
	    console.log('Resolving connection waiter.');
	    this.connectionResolution();
	}
    }

    _onPeerConnection(c) {
	console.log(`Peer connection. Other: ${c.peer}`);
	this._updateStatus(`Peer connected to: ${c.peer}`);
	this.otherId = c.peer;
	this.conn = c;
	this._addConnHandlers();
    }

    _onPeerDisconnected() {
	console.log('Peer disconnected');
	this._updateStatus("Peer disconnected.");
    }

    _onPeerClose() {
	console.log('Peer close');
	this._updateStatus("Peer closed.");
    }

    _onPeerError(err) {
	console.log(`Peer error`);
	console.log(err);
	this._updateStatus(`Peer error: ${err.message}`);
	if (err.message === `ID "${this.channelId}" is taken`) {
	    // We are the client, so reinitialize with 'null'.
	    this._initialize(null);
	}
    }

    _onPeerCall(mediaConnection) {
	console.log(`Peer call from ${mediaConnection.peer}`);
	this._updateStatus(`Peer call from: ${mediaConnection.peer}`);
	if (mediaConnection.peer == this.peer.id) {
	    console.log('Self call.  Ignore.');
	    this._updateStatus("Self call.  Ignored.");
	}
	const audioCtx = this.peerOutputNode.context;
	const outgoingStream =
	      audioCtx.createMediaStreamDestination();
	this.peerOutputNode.connect(outgoingStream);

	mediaConnection.answer(outgoingStream.stream);
	mediaConnection.on(
	    'stream',
	    (incomingStream) => this._handleIncomingStream(incomingStream));
    }

    _handleIncomingStream(incomingStream) {
	console.log('Stream Received');
	this._updateStatus("Stream received.");
	// Ideally, we want to disconnect anything coming into the
	// peerInputNode
	//if (this.peerInputNode) {
	//    this.peerInputNode.disconnect();
	//}
	console.log('Hack is here.');
	// Ungodly hack to actually get the audio to flow
	const a = new Audio();
	a.muted = true;
	a.srcObject = incomingStream;
	a.addEventListener('canplaythrough', () => {
	    console.log('ready to flow'); });
	
	// Properly handle stream and create media source node
	const audioCtx = this.peerInputNode.context;
	const peerInputStream = audioCtx.createMediaStreamSource(
	    incomingStream);
	peerInputStream.connect(this.peerInputNode);
    }

    async _join() {
	console.log('join');
	this._updateStatus("Joining peer...");
	if (this.conn) {
	    this.conn.close();
	}
	this.conn = this.peer.connect(this.otherId);
	this._addConnHandlers();

	const audioCtx = this.peerOutputNode.context;
	const peerOutputStream = audioCtx.createMediaStreamDestination();
	this.peerOutputNode.connect(peerOutputStream);

	console.log(`Calling ${this.otherId}`);
	const mediaConnection = this.peer.call(
	    this.otherId, peerOutputStream.stream);
	mediaConnection.on('stream', (incomingStream) => {
	    console.log('Hack is here.');
	    // Ungodly hack to actually get the audio to flow
	    const a = new Audio();
	    a.muted = true;
	    a.srcObject = incomingStream;
	    a.addEventListener('canplaythrough', () => {
		console.log('ready to flow'); });
	    // End ungodly hack.
	    console.log('Got callee stream.');
	    this._updateStatus("Receiving audio stream from peer.");
	    const peerSourceStream =
		  audioCtx.createMediaStreamSource(incomingStream);
	    peerSourceStream.connect(this.peerInputNode);
	});
    }
    
}

```

```js worklet-recorder.js
class WorkletRecorder extends AudioWorkletProcessor {
    first = true;

    process(inputs) {
      if (inputs.length == 0) { return; }
      const channels = inputs[0];
      if (channels.length == 0) { return; }
      const samples = channels[0];
      // Caller expects monophonic data, so only return the first channel.
      this.port.postMessage({ 
        timestamp: currentTime,
        frame: currentFrame,
        samples: samples, 
      });
      return true;
    }
}

registerProcessor('worklet-recorder', WorkletRecorder);
```

```md readme.md
# Product Requirements Document: Collaborative Music Workspace

Connecting musicians and empowering their creativity.

## 1. Introduction

This document outlines the requirements for a collaborative music
workspace application. The application aims to provide musicians with
a platform to create, share, and refine musical ideas in real-time,
regardless of their physical location.


## 2. Goals

* Enable real-time musical collaboration between two users.

* Provide tools for sharing and developing musical ideas, including
    lyrics, chords, and audio recordings.

* Offer high-quality audio transmission for remote collaboration and
    songwriting sessions.

* Maintain a user-friendly and intuitive interface.

## 3. Target Audience

* Musicians (instrumentalists, vocalists, songwriters, composers).

* Music educators and students.

* Songwriting partners.

* Music producers

## 4. Features

### 4.1 Core Features

* **Peer-to-Peer Audio Connection:**

    * Establish and maintain low-latency audio connections with no noise
    reduction, compression, or other effects that are ineffective for
    music collaboration.
    
    * Support selection of audio input and output devices.
    
    * Provide individual gain control for monitoring and controlling outgoing
        and incoming signals.
    
* **Shared Scratch Pad:**

    * Real-time collaborative text editor.
    
    * Specific formatting options for chords and lyric lines.
        
* **Audio Recording & Sharing:**

    * Ability to record audio snippets locally.

    * Metronome with count-in options
    
    * Audio snippets are immediately shared with other participants
    
    * Playback controls for shared audio.
    
    * Visual representation of audio (e.g. waveform)

    * Simple arrangement of audio with lyrics

    * Shared BPM, measures per line, "tape rate" configuration


### 4.2 Future Enhancements (Out of Scope for Initial Release)

* Instrument tuner.

*   Advanced audio effects processing.

*   Integration with digital audio workstations (DAWs).

*   Video conferencing.

## 5. Technical Requirements

* **Platform:** Web-based application (cross-platform compatibility).

* **Technology Stack:** JavaScript, HTML, CSS, Web Audio API, WebRTC,
      IndexedDB.

* **Performance:** High quality audio recording and transmission is
    critical. Near immediate synchronization of song edits are
    essential.

* **Scalability:** The system should be able to handle two concurent
    users and sixteen simultaneous audio tracks.

* **Security:** Secure peer-to-peer connection and data transmission.

##6. User Interface (UI) and User Experience (UX) - Detailed MVP Design

The core goal is to facilitate real-time musical collaboration. The UI/UX should be simple, functional, and not get in the way of the creative process.

###6.1. Overall Layout:

*   **Split Screen:** The interface will be divided into two main areas:

    * **Shared Workspace:** The main area where the shared text
          editor, recorded audio snippets, metronome, and other
          collaborative tools are located.
    
    * **Local Control Panel:** A top bar that
          provides controls for audio settings, input/output
          selection, gain adjustment, and user-specific controls.
    
* **Clean Design:** The UI should avoid unnecessary visual
      clutter. Use clear icons and simple typography.

* **Responsive Design:** The layout should adapt to different screen
      sizes (desktop, tablets).

###6.2. Shared Workspace:

* **Real-time Text Editor:** A large, editable text area where users
    can write lyrics, chord progressions, and notes.
    
    * Real-time updates: When one user types, the changes should
        appear immediately on the other user's screen.
    
    *   Basic Formatting:
    
        *   Simple markup for chords (e.g., `[C]`, `[Am]`) to be displayed differently.
	
        *   Clear distinction between lyric lines and other notations.
	
*   **Audio Snippets:**

    * Audio snippets are displayed directly below or above the lyrics
        they correspond to.
    
    *   Each snippet will have:
    
        *   A waveform display for visual representation.
	
        *   The ability to be dragged and dropped for simple arrangement.
	
        *   Visual alignment of audio to beats and bars (grid-like).
	
*   **Metronome & Tempo:**

    *   A simple start/stop control for the metronome.
    
    *   Display for the current tempo (BPM).
    
    *   Input field to change BPM.
    
    *   Count-in option.
    
*   **Track Settings**

    *  Number of measures in a line
    
    *  "Tape speed"

###6.3. Local Control Panel:

*   **Audio Input/Output:**

    * Dropdown menus or radio buttons to select audio input and output
        devices.
    
    * Clear labels indicating the selected input and output devices.
    
* **Gain Controls:**

    * Individual sliders for adjusting the local input gain, the gain
        of audio being sent to the peer, and the gain of audio
        received from the peer.
    
* **Push to Talk:**

    When musician 1 starts playback, musician 2 can hear it.  Musician
    2 is muted unless they hold a button to talk.  This prevents
    musician 2 from transmitting their playing back to musician 1.
    Musician 1 would hear this with a significant delay which would
    make it difficult for musician 1 to play.  When muted, a musician
    can record.
    
* **Recording Controls:**

    * A prominent record button.
    
    * A visual indicator to show that recording is in progress.
    
    * The recording will be added to the "Audio Snippet Area".

###6.4. User Experience (UX) Principles:

* **Real-Time Feedback:** Provide visual cues for all actions, e.g.,
      when audio is playing, when recording is in progress, when a
      connection is made.

* **Intuitive Controls:** Make the controls easily accessible and
      understandable without requiring a tutorial.

* **Minimalist Approach:** Avoid unnecessary UI elements and
      animations. Focus on whats essential for real-time
      collaboration.

* **Low Latency:** Strive for the lowest possible latency between
      actions and their effects.

* **Clear Communication:** Provide clear messaging for status updates,
      errors, and other important information.

###6.5. Workflow Example:

1.  **Setup:**

* Both users open the web application and a peer-to-peer connection is
    automatically established.
    
    * Both users select their audio input/output devices and adjust
        gain levels.

2.  **Songwriting:**

    * One user starts typing lyrics and chords in the shared text
        editor. The other user sees the changes in real-time.
    
    * One user sets the tempo

3.  **Recording & Sharing:**

    * One user starts recording.  The metronome clicks, and the other
    user can hear the metronome and what the first user is playing.
    
    * The recorded snippet appears as a waveform in the shared audio
        area.

    * Either user can now play back the recorded audio.

4.  **Refining:**

    * The users drag the audio snippets and arrange them to create a
       basic song structure.
    
    * The users work together to refine lyrics, timing, and tempo.

**In Summary:**

The MVP should prioritize providing a simple, efficient, and real-time
platform for musicians to collaborate. The UI/UX design will focus on
these key elements:

*   Real-time text editor with chord notation.

*   Simple audio recording and sharing with waveform display.

*   Local gain adjustment and audio device selection.

*   Metronome controls.

*   A clear "push to talk" feature.

This will allow musicians to start creating, sharing, and iterating on
ideas with minimal friction.

## 7. Release Criteria

* All core features implemented and tested.

* Stable and reliable audio connections.

* User-friendly interface with clear instructions.

* Basic error handling and informative messages.

## 8. Future Considerations

* Monetization strategy (e.g., subscription, premium features).

* Community features (e.g., public jam sessions, user profiles).

* Mobile application development.

```

You are working with a professional software developer.  You don't need to
explain the code you produce.  Please prefer short answers to longer ones.
For small changes, describing the change with a few lines of code is preferred
over rewriting the entire project.
When significant changes are required to a file, present the entire file.
Sometimes you will be asked for design advice.  Please provide the advice without
producing any code.
Prefer writing JavaScript classes to "naked" functions.
